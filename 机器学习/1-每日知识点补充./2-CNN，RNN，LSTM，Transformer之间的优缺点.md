1、CNN 卷积神经网络;
    
    🐤 CNN---固定（几何结构）的卷积神经网络组成；主要用于识别位移，缩放及其它扭曲不变性的二维图像
    【优点】
      （1）由于CNN的特征检测层通过训练数据进行学习，所以能够避免显性的特征抽取，并隐式地从训练数据中进行学习。
      （2）局部权值共享，平移不变性；可以更好的提取特征以及处理高维的数据；
    【缺点】
      （1）当网络层数太深时候，采用BP调整欸不参数会使得接近输入层的变化较慢；
      （2）采用BP进行迭代时候很容易使得训练结果收敛于【局部最优】，而非全局最优；
      （3）池化层，会丢失一定的有价值信息，忽略了局部与整体之间的关联性；
      （4）特征提取的物理含义不是十分明确，导致可解释性一般；
      
      
2、RNN 循环神经网络
    RNN对具有序列特性的数据非常有效，它能挖掘数据中的时序信息以及语义信息，利用了RNN的这种能力，使深度学习模型在解决语音识别、语言模型、机器翻译以及时序分析等NLP领域的问题时有所突破
    【优点】
    传统网络（traditional network）无法结合上下文去训练网络，而RNN的结构决定了其具有短期记忆性，每一时刻隐藏层信息不仅由该时刻的输入层决定
    【缺点】
    随着网络的层数增加，RNN在长时序列场景处理时会出现梯度爆炸的弊端（BP算法的局限性导致）


3、LSTM 
    【】
    【】
4、Transformer
    【】
    【】  
    
    
    
![图片](https://user-images.githubusercontent.com/38878365/188896231-8070d50b-571d-4e75-a2a6-30892b51dcfe.png)
    
