标准化和归一化；

######################################
######1、为什么经常要对数据归一化？#######
######################################

一般做机器学习应用的时候大部分时间花费在【特征处理】上，其中关键一步是对特征数据归一化？
优点：

【1、归一化后加快了梯度下降求最优解的速度】
![图片](https://user-images.githubusercontent.com/38878365/180198779-cec5030a-d0ee-41fe-a7f2-55aa33e6cf08.png)


【2、归一化有可能提高精度】

一些【分类器】需要计算样本之间的距离，例如欧氏距离、KNN等。如果一个特征值域范围非常大，那么距离计算就可能就取决于该特征值，
从而与实际情况相悖（比如实际上特征值范围小的特征更重要）

![图片](https://user-images.githubusercontent.com/38878365/180199626-c9a8f710-293f-4677-9629-2a0acd471ac2.png)









######################################
######1、归一化的类型有哪些？###########
######################################


1、线性归一化：
通过对原始数据进行线性变换吧数据映射到【0，1】之间，变换函数为：
![图片](https://user-images.githubusercontent.com/38878365/180199807-966296c2-e851-4242-8460-3d6fd9f4afd5.png)
【适用范围】
数值比较集中的情况
【缺点】
如果max和min不稳定，很容易使得归一化的结果不稳定。而实际使用中经常使用【经验常数】来代替max和min



2、标准差标准化

经过处理的数据符合标准正态分布，均值为0，方差为1；
![图片](https://user-images.githubusercontent.com/38878365/180200273-baef68b2-0b80-4e68-ae14-728bd2681d17.png)
【适用条件】
原始数据的分布可以近似为高斯分布，否则标准化的效果会变得很差。---可以先通过样本估计。适用于样本数量足够多



3、非线性归一化；

经常用在【数据分化比较大】的场景；
【使用环境】
通过一些数学函数，将原始值进行映射。该方法包括log、指数、正切等
需要根据数据分布的情况，决定非线性函数的曲线。



######################################
######1、哪些情况下需要归一化？##########
######################################

实际应用中，通过对【梯度下降法】----BP算法，需要进行归一化
【线性回归、logistic回归、knn、SVM、神经网络等】
![图片](https://user-images.githubusercontent.com/38878365/180201147-0a93a1b5-aa75-443c-9fdf-172d14c49ebd.png)











